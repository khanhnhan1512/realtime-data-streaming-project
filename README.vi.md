<h1 align="center">Realtime Data Streaming Pipeline</h1>

<p align="center">
  <a href="README.md">English</a> Â·
  <a href="README.vi.md">Tiáº¿ng Viá»‡t</a>
</p>

ÄÃ¢y lÃ  dá»± Ã¡n cÃ¡ nhÃ¢n xÃ¢y dá»±ng má»™t pipeline realtime streaming sá»­ dá»¥ng `Apache Kafka`, `Apache Spark Streaming` vÃ  `Apache Airflow`. Má»¥c tiÃªu cá»§a pipeline lÃ  thu tháº­p dá»¯ liá»‡u ngÆ°á»i dÃ¹ng tá»« má»™t API giáº£ láº­p, xá»­ lÃ½ dá»¯ liá»‡u theo thá»i gian vÃ  lÆ°u trá»¯ chÃºng vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u `Cassandra`.

KhÃ´ng cÃ³ viá»‡c xá»­ lÃ½ dá»¯ liá»‡u nÃ o quÃ¡ phá»©c táº¡p trong pipeline nÃ y, má»¥c Ä‘Ã­ch cá»§a project nÃ y chá»‰ lÃ  Ä‘á»ƒ lÃ m quen vá»›i viá»‡c sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ phá»• biáº¿n trong lÄ©nh vá»±c xá»­ lÃ½ dá»¯ liá»‡u lá»›n vÃ  realtime streaming.

# Má»¥c lá»¥c
- [Tá»•ng quan](#tá»•ng-quan)
- [Kiáº¿n trÃºc pipeline](#kiáº¿n-trÃºc-pipeline)
- [Cáº¥u trÃºc thÆ° má»¥c](#cáº¥u-trÃºc-thÆ°-má»¥c)
- [Luá»“ng dá»¯ liá»‡u](#luá»“ng-dá»¯-liá»‡u)
- [CÃ´ng nghá»‡ sá»­ dá»¥ng](#cÃ´ng-nghá»‡-sá»­-dá»¥ng)
- [YÃªu cáº§u cÃ i Ä‘áº·t](#yÃªu-cáº§u-cÃ i-Ä‘áº·t)
- [HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  khá»Ÿi cháº¡y](#hÆ°á»›ng-dáº«n-cÃ i-Ä‘áº·t-vÃ -khá»Ÿi-cháº¡y)
- [GiÃ¡m sÃ¡t vÃ  quáº£n lÃ½](#giÃ¡m-sÃ¡t-vÃ -quáº£n-lÃ½)

# Tá»•ng quan

Pipeline nÃ y Ä‘Æ°á»£c xÃ¢y dá»±ng nháº±m má»¥c Ä‘Ã­ch há»c táº­p vÃ  lÃ m quen vá»›i cÃ¡c cÃ´ng cá»¥ xá»­ lÃ½ dá»¯ liá»‡u lá»›n vÃ  realtime streaming. Dá»¯ liá»‡u ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c giáº£ láº­p tá»« má»™t API Ä‘Æ¡n giáº£n, sau Ä‘Ã³ Ä‘Æ°á»£c gá»­i vÃ o Kafka Ä‘á»ƒ xá»­ lÃ½ theo thá»i gian thá»±c báº±ng Spark Streaming. Cuá»‘i cÃ¹ng, dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ sáº½ Ä‘Æ°á»£c lÆ°u trá»¯ vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u Cassandra Ä‘á»ƒ phá»¥c vá»¥ cho cÃ¡c má»¥c Ä‘Ã­ch phÃ¢n tÃ­ch sau nÃ y.

# Kiáº¿n trÃºc pipeline
![Pipeline Architecture](./images/pipeline-architecture.svg)

# Cáº¥u trÃºc thÆ° má»¥c
```
â”œâ”€â”€ ğŸ“ airflow
â”‚   â”œâ”€â”€ ğŸ“ dags                             # chá»©a cÃ¡c DAGs cho Apache Airflow
â”‚   â”‚   â””â”€â”€ ğŸ kafka_stream.py
â”‚   â””â”€â”€ ğŸ³ Dockerfile                       # Dockerfile Ä‘á»ƒ xÃ¢y dá»±ng image Airflow 
â”œâ”€â”€ ğŸ“ api-request                          
â”‚   â”œâ”€â”€ ğŸ“ src      # ÄÃ³ng gÃ³i `user_data_api` thÃ nh 1 package Ä‘á»ƒ cháº¡y trÃªn mÃ´i trÆ°á»ng local
â”‚   â”‚   â”œâ”€â”€ ğŸ“ api_request.egg-info         
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ PKG-INFO
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ SOURCES.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ dependency_links.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“„ requires.txt
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“„ top_level.txt
â”‚   â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”‚   â””â”€â”€ ğŸ user_data_api.py             # Script láº¥y data tá»« API
â”‚   â”œâ”€â”€ ğŸ“ README.md
â”‚   â”œâ”€â”€ ğŸ __init__.py
â”‚   â”œâ”€â”€ ğŸ main.py
â”‚   â””â”€â”€ âš™ï¸ pyproject.toml
â”œâ”€â”€ ğŸ“ config
â”‚   â””â”€â”€ ğŸ“„ airflow.cfg
â”œâ”€â”€ ğŸ“ images                               # Chá»©a cÃ¡c file áº£nh
â”‚   â”œâ”€â”€ ğŸ“„ pipeline-architecture.drawio
â”‚   â”œâ”€â”€ ğŸ–¼ï¸ pipeline-architecture.png
â”‚   â””â”€â”€ ğŸ–¼ï¸ pipeline-architecture.svg
â”œâ”€â”€ ğŸ“ script                  # Chá»©a entrypoint cho cÃ¡c service
â”œâ”€â”€ ğŸ“ spark
â”‚   â”œâ”€â”€ ğŸ³ Dockerfile          # Dockerfile Ä‘á»ƒ xÃ¢y dá»±ng custom image Spark 
â”‚   â””â”€â”€ ğŸ spark_stream.py     # Script cháº¡y Spark job
â”œâ”€â”€ âš™ï¸ .dockerignore
â”œâ”€â”€ âš™ï¸ .gitignore
â”œâ”€â”€ ğŸ“ README.md
â”œâ”€â”€ âš™ï¸ docker-compose.airflow3.yaml # Docker Compose cho Apache Airflow
â”œâ”€â”€ âš™ï¸ docker-compose.kafka.yaml    # Docker Compose cho Apache Kafka
â”œâ”€â”€ âš™ï¸ docker-compose.spark.yaml    # Docker Compose cho Apache Spark
â”œâ”€â”€ âš™ï¸ pyproject.toml               # File cáº¥u hÃ¬nh quáº£n lÃ½ mÃ´i trÆ°á»ng áº£o báº±ng uv
â”œâ”€â”€ ğŸ“„ requirements.txt             # File chá»©a cÃ¡c dependencies cá»§a mÃ´i trÆ°á»ng áº£o
â”œâ”€â”€ ğŸ“„ stop-pipeline.sh             # Shell script Ä‘á»ƒ dá»«ng toÃ n bá»™ pipeline
â””â”€â”€ ğŸ“„ uv.lock                      # File khÃ³a mÃ´i trÆ°á»ng áº£o cá»§a uv
```
# Luá»“ng dá»¯ liá»‡u
1. Dá»¯ liá»‡u giáº£ láº­p vá» ngÆ°á»i dÃ¹ng Ä‘Æ°á»£c láº¥y tá»« [API](https://randomuser.me/api). API nÃ y cung cáº¥p dá»¯ liá»‡u ngÆ°á»i dÃ¹ng ngáº«u nhiÃªn vá»›i cÃ¡c thÃ´ng tin nhÆ° tÃªn, Ä‘á»‹a chá»‰ email, quá»‘c gia, v.v.
2. Dá»¯ liá»‡u cá»§a tá»«ng ngÆ°á»i dÃ¹ng (record) Ä‘Æ°á»£c gá»­i Ä‘áº¿n má»™t chá»§ Ä‘á» (topic) trong Apache Kafka thÃ´ng qua má»™t producer.
3. Apache Airflow Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘iá»u phá»‘i 2 quÃ¡ trÃ¬nh trÃªn.
4. Apache Spark Streaming Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘á»ƒ láº¯ng nghe chá»§ Ä‘á» Kafka vÃ  nháº­n dá»¯ liá»‡u theo thá»i gian thá»±c.
5. Dá»¯ liá»‡u nháº­n Ä‘Æ°á»£c tá»« Kafka sáº½ Ä‘Æ°á»£c Spark nháº­n, truyá»n Ä‘i vÃ  lÆ°u trá»¯ vÃ o cÆ¡ sá»Ÿ dá»¯ liá»‡u Cassandra.

# CÃ´ng nghá»‡ sá»­ dá»¥ng
| CÃ´ng nghá»‡        | Chá»©c nÄƒng                                                                                      |
|------------------|------------------------------------------------------------------------------------------------|
| Docker           | ÄÃ³ng gÃ³i vÃ  cháº¡y toÃ n bá»™ cÃ¡c service                                                           |
| Apache Kafka     | Tiáº¿p nháº­n vÃ  lÆ°u trá»¯ cÃ¡c record vá»›i lÆ°u lÆ°á»£ng cao                                              |
| Zookeeper        | Quáº£n lÃ½, Ä‘iá»u phá»‘i Kafka Cluster                                                               |
| Schema Registry  | Quáº£n lÃ½ vÃ  xÃ¡c thá»±c schema cho cÃ¡c record gá»­i tá»›i Kafka                                        |
| Control Center   | Giao diá»‡n Ä‘á»ƒ quáº£n lÃ½ vÃ  giÃ¡m sÃ¡t Kafka Cluster                                                 |
| Spark Streaming  | Láº¯ng nghe 1 topic tá»« Kafka vÃ  truyá»n dá»¯ liá»‡u má»›i trong topic Ä‘áº¿n Cassandra theo thá»i gian thá»±c |
| Apache Cassandra | CÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘á»ƒ lÆ°u trá»¯ record thá»i gian thá»±c                                                 |
| Apache Airflow   | GiÃ¡m sÃ¡t vÃ  Ä‘iá»u phá»‘i cÃ¡c cÃ´ng viá»‡c trong pipeline                                             |
| PostgresSQL      | LÆ°u trá»¯ metadata cho Airflow                                                                   |
# YÃªu cáº§u cÃ i Ä‘áº·t
Äá»ƒ cháº¡y Ä‘Æ°á»£c project nÃ y cáº§n cÃ¡c Ä‘iá»u kiá»‡n sau:
- CÃ i Ä‘áº·t Docker vÃ  Docker Compose.
- Python 3.11
- MÃ´i trÆ°á»ng áº£o cÃ³ cÃ¡c thÆ° viá»‡n nhÆ° trong `requirements.txt`.
- File `.env` chá»©a cÃ¡c biáº¿n mÃ´i trÆ°á»ng Ä‘á»ƒ cháº¡y Ä‘Æ°á»£c cÃ¡c service cá»§a `Airflow` nhÆ°:
    - `AIRFLOW_UID`
    - `AIRFLOW_GID`
    - `AIRFLOW_PROJ_DIR`
    - `_AIRFLOW_WWW_USER_USERNAME`
    - `_AIRFLOW_WWW_USER_PASSWORD`
# HÆ°á»›ng dáº«n cÃ i Ä‘áº·t vÃ  khá»Ÿi cháº¡y
1. Clone repository nÃ y vá» mÃ¡y cá»§a báº¡n:
    ```bash
    git clone https://github.com/khanhnhan1512/realtime-data-streaming-project.git
    ```
2. Di chuyá»ƒn vÃ o thÆ° má»¥c dá»± Ã¡n:
    ```bash
    cd realtime-data-streaming-project
    ```
3. Táº¡o vÃ  kÃ­ch hoáº¡t mÃ´i trÆ°á»ng áº£o:
    - Náº¿u sá»­ dá»¥ng `uv`:
        ```bash
        uv init
        uv sync
        ```
    - Náº¿u sá»­ dá»¥ng `venv`:
        ```bash
        python3 -m venv venv
        source venv/bin/activate
        pip install -r requirements.txt
        ```
4. Cháº¡y Docker Compose Ä‘á»ƒ khá»Ÿi Ä‘á»™ng toÃ n bá»™ pipeline:
    ```bash
    docker-compose -f docker-compose.kafka.yaml up -d # Ä‘á»£i khoáº£ng 20s Ä‘á»ƒ Kafka khá»Ÿi Ä‘á»™ng xong
    docker-compose -f docker-compose.airflow3.yaml up -d  # Ä‘á»£i khoáº£ng 20s Ä‘á»ƒ khá»Ÿi Ä‘á»™ng Airflow
    docker-compose -f docker-compose.spark.yaml up -d  # khá»Ÿi Ä‘á»™ng Spark
    ```
5. Dá»«ng toÃ n bá»™ pipeline:
    ```bash
    ./stop-pipeline.sh
    ```
# GiÃ¡m sÃ¡t vÃ  quáº£n lÃ½
- Control Center cá»§a Kafka: [http://localhost:9021](http://localhost:9021)
- Giao diá»‡n web cá»§a Airflow: [http://localhost:8081](http://localhost:8081) (username vÃ  password Ä‘Æ°á»£c cáº¥u hÃ¬nh trong file `.env`, máº·c Ä‘á»‹nh lÃ  admin/admin)
- Giao diá»‡n web cá»§a Spark: [http://localhost:9090](http://localhost:9090)