services:
  spark-base:
    build:
      context: .
      dockerfile: ./spark/Dockerfile
    image: custom-spark:latest
    container_name: spark-base

  spark-master:
    image: custom-spark:latest
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    depends_on:
      - spark-base
    volumes:
      - ./spark/spark_stream.py:/opt/spark/apps/spark_stream.py
    ports:
      - 9090:8080
      - 7077:7077
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no

  spark-worker:
    image: custom-spark:latest
    container_name: spark-worker-0
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-base
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
  
  # spark-worker-1:
  #   image: bitnami/spark:latest
  #   container_name: spark-worker-2
  #   command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
  #   depends_on:
  #     - spark-master
  #   environment:
  #     SPARK_MODE: worker
  #     SPARK_WORKER_CORES: 2
  #     SPARK_WORKER_MEMORY: 1g
  #     SPARK_MASTER_URL: spark://spark-master:7077

  cassandra_db:
    image: cassandra:latest
    container_name: cassandra_db
    hostname: cassandra
    ports:
      - 9042:9042
    environment:
      MAX_HEAP_SIZE: 512M
      HEAP_NEWSIZE: 100M
      CASSANDRA_USERNAME: cassandra
      CASSANDRA_PASSWORD: cassandra
    healthcheck:
      test: ["CMD-SHELL", "cqlsh -u cassandra -p cassandra -e 'describe keyspaces'"]
      interval: 15s
      timeout: 10s
      retries: 10

networks:
  default:
    external: true
    name: realtime-data-streaming-project_confluent